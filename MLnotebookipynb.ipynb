{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "class LinearRegressionScratch:\n",
        "  def __init__ (self, learning_rate=0.001,epochs = 1000,verbose = False):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.epochs = epochs\n",
        "    self.verbose = verbose\n",
        "    self.weights = None\n",
        "    self.bias = None\n",
        "\n",
        "  def fit(self,X,y):\n",
        "    num_samples = X.shape[0]\n",
        "    num_features = X.shape[1]\n",
        "    self.weights = np.random.rand(num_features)\n",
        "    self.bias = 0\n",
        "\n",
        "    for epoch in range(self.epochs):\n",
        "      y_preds = X.dot(self.weights) + self.bias\n",
        "      dw = 2/num_samples * X.T.dot(y_preds-y)\n",
        "      db = 2/num_samples * np.sum(y_preds-y)\n",
        "      self.weights -= dw * self.learning_rate\n",
        "      self.bias -= db * self.learning_rate\n",
        "\n",
        "      if epoch%100 == 0 and self.verbose:\n",
        "        loss = np.mean((y-y_preds)**2)\n",
        "        print(f\"epoch {epoch} = {loss}\")\n",
        "\n",
        "\n",
        "  def predict(self,X):\n",
        "    y_preds = X.dot(self.weights) + self.bias\n",
        "    return y_preds\n"
      ],
      "metadata": {
        "id": "XYqFnRDt9KZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create synthetic data: y = 4 + 3x + noise\n",
        "np.random.seed(24)\n",
        "X = 2 * np.random.rand(100, 1)\n",
        "y = 4 + 3 * X + np.random.randn(100, 1)\n",
        "\n",
        "# Flatten y to 1D array for simplicity\n",
        "y = y.flatten()\n",
        "\n",
        "# Instantiate and train the model\n",
        "model = LinearRegressionScratch(learning_rate=0.01, epochs=1000,verbose = True)\n",
        "model.fit(X, y)\n",
        "\n",
        "# Make predictions on the training data\n",
        "predictions = model.predict(X)\n",
        "\n",
        "# Print the first 5 predictions and actual values\n",
        "print(\"Predictions:\", predictions[:5])\n",
        "print(\"Actual:\", y[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuMAjCJIBONe",
        "outputId": "289967d5-d4d6-41d1-b3c7-77987bb3a9c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 = 47.645564339829946\n",
            "epoch 100 = 1.1601923521611341\n",
            "epoch 200 = 1.0587888779456276\n",
            "epoch 300 = 1.0019956630000397\n",
            "epoch 400 = 0.9694164817709912\n",
            "epoch 500 = 0.9507275349601905\n",
            "epoch 600 = 0.940006678272282\n",
            "epoch 700 = 0.9338566919040696\n",
            "epoch 800 = 0.9303287711949103\n",
            "epoch 900 = 0.9283049903627374\n",
            "Predictions: [ 9.86023544  8.26043754 10.1049596   5.31610264  6.18193545]\n",
            "Actual: [ 9.61267695  9.75837997 10.68391375  5.34986616  5.3138632 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegressionScratch:\n",
        "  def __init__(self,learning_rate = 0.001, epochs = 1000,verbose = False):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.epochs = epochs\n",
        "    self.verbose = verbose\n",
        "    self.weights = None\n",
        "    self.bias = None\n",
        "\n",
        "  def sigmoid(self,X):\n",
        "    return 1/(1+np.exp(-X))\n",
        "\n",
        "  def fit(self,X,y):\n",
        "    num_samples = X.shape[0]\n",
        "    num_features = X.shape[1]\n",
        "    self.weights = np.random.randn(num_features)\n",
        "    self.bias = 0\n",
        "\n",
        "    for epoch in range(self.epochs):\n",
        "      z = X.dot(self.weights) + self.bias\n",
        "      y_preds = self.sigmoid(z)\n",
        "      dw = 1/num_samples * X.T.dot(y_preds-y)\n",
        "      db = 1/num_samples * np.sum(y_preds-y)\n",
        "\n",
        "      self.weights -= dw * self.learning_rate\n",
        "      self.bias -= db * self.learning_rate\n",
        "\n",
        "      if self.verbose and epoch % 100 == 0:\n",
        "        epsilon = 1e-15\n",
        "        loss = - 1 / num_samples * np.sum(y * np.log(y_preds+epsilon) + (1-y) * np.log(1-y_preds+epsilon))\n",
        "        print(f\"epoch {epoch} loss = {loss}\")\n",
        "\n",
        "  def predict(self,X):\n",
        "    z = X.dot(self.weights) + self.bias\n",
        "    y_preds = self.sigmoid(z)\n",
        "    return (y_preds>=0.5).astype(int)\n",
        "\n",
        "  def accuracy(self,X,y):\n",
        "    y_preds = self.predict(X)\n",
        "    return np.mean(y_preds == y)\n"
      ],
      "metadata": {
        "id": "qEJG8z_P9XT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Generate dummy binary classification data\n",
        "X, y = make_classification(n_samples=500, n_features=5, n_informative=3, n_redundant=0, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegressionScratch(learning_rate=0.1, epochs=1000,verbose=True)\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Train Accuracy:\", model.accuracy(X_train, y_train))\n",
        "print(\"Test Accuracy:\", model.accuracy(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mn2jgE99WOYx",
        "outputId": "567348eb-8216-4264-d449-e11a7a71a2b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 loss = 1.2280363329325863\n",
            "epoch 100 loss = 0.31134343648661256\n",
            "epoch 200 loss = 0.29804721038330917\n",
            "epoch 300 loss = 0.2942835737137249\n",
            "epoch 400 loss = 0.29286779622857684\n",
            "epoch 500 loss = 0.29226968728198666\n",
            "epoch 600 loss = 0.2920005917412164\n",
            "epoch 700 loss = 0.29187483679695864\n",
            "epoch 800 loss = 0.29181462328936186\n",
            "epoch 900 loss = 0.291785323903164\n",
            "Train Accuracy: 0.885\n",
            "Test Accuracy: 0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "  def __init__(self, feature_index = None, threshhold=None,left=None,right=None,value=None):\n",
        "    self.feature_index = feature_index\n",
        "    self.threshhold=threshhold\n",
        "    self.left = left\n",
        "    self.right = right\n",
        "    self.value = value\n",
        "\n",
        "class DecisionTreeScratch:\n",
        "  def __init__(self, max_depth = 5,min_samples_split = 5):\n",
        "    self.root = None\n",
        "    self.max_depth = max_depth\n",
        "    self.min_samples_split = min_samples_split\n",
        "\n",
        "  def fit(self,X,y):\n",
        "    self.root = self.build_tree(X,y,depth = 0)\n",
        "\n",
        "  def build_tree(self, X, y, depth):\n",
        "      if len(X) <= self.min_samples_split or len(np.unique(y)) == 1 or depth == self.max_depth:\n",
        "          leaf_value = self._most_common(y)\n",
        "          return Node(value=leaf_value)\n",
        "\n",
        "      parent_entropy = self._entropy(y)\n",
        "\n",
        "      best_ig = -float('inf')\n",
        "      best_feature_index = None\n",
        "      best_threshold = None\n",
        "      best_left_X, best_left_y = None, None\n",
        "      best_right_X, best_right_y = None, None\n",
        "\n",
        "      for feature_index in range(X.shape[1]):\n",
        "          feature_values = np.sort(np.unique(X[:, feature_index])) #gets all unique features in this current feature and sorts them\n",
        "          thresholds = (feature_values[:-1] + feature_values[1:]) / 2 #threshholds are between each unique point\n",
        "\n",
        "          for threshold in thresholds:\n",
        "              left_mask = X[:, feature_index] <= threshold #splits X into groups based on threshhold\n",
        "              right_mask = X[:, feature_index] > threshold\n",
        "              X_left, y_left = X[left_mask], y[left_mask]\n",
        "              X_right, y_right = X[right_mask], y[right_mask]\n",
        "\n",
        "              if len(y_left) == 0 or len(y_right) == 0:\n",
        "                  continue  # Skip invalid splits\n",
        "\n",
        "              weighted_entropy = (len(y_left) / len(y)) * self._entropy(y_left) + (len(y_right) / len(y)) * self._entropy(y_right)\n",
        "              information_gain = parent_entropy - weighted_entropy\n",
        "\n",
        "              if information_gain > best_ig:\n",
        "                  best_ig = information_gain\n",
        "                  best_feature_index = feature_index\n",
        "                  best_threshold = threshold\n",
        "                  best_left_X, best_left_y = X_left, y_left\n",
        "                  best_right_X, best_right_y = X_right, y_right\n",
        "\n",
        "      # If no good split found, make a leaf\n",
        "      if best_ig == -float('inf'):\n",
        "          leaf_value = self._most_common(y)\n",
        "          return Node(value=leaf_value)\n",
        "\n",
        "      # Recursively build left and right subtrees\n",
        "      left_child = self.build_tree(best_left_X, best_left_y, depth + 1)\n",
        "      right_child = self.build_tree(best_right_X, best_right_y, depth + 1)\n",
        "\n",
        "      # Return a decision node\n",
        "      return Node(feature_index=best_feature_index, threshhold=best_threshold, left=left_child, right=right_child)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def predict(self,X):\n",
        "    return np.array([self._traverse_tree(x, self.root) for x in X])\n",
        "\n",
        "\n",
        "  def _traverse_tree(self, x, node):\n",
        "      if node.value is not None:\n",
        "          return node.value\n",
        "\n",
        "      feature_value = x[node.feature_index]\n",
        "      if feature_value <= node.threshhold:\n",
        "        return self._traverse_tree(x,node.left)\n",
        "      else:\n",
        "        return self._traverse_tree(x,node.right)\n",
        "\n",
        "\n",
        "\n",
        "  def _entropy(self,y):\n",
        "    values,counts = np.unique(y,return_counts=True)\n",
        "    probabilities = counts/len(y)\n",
        "    entropy = - np.sum(probabilities * np.log2(probabilities))\n",
        "    return entropy\n",
        "\n",
        "  def _most_common(self,y):\n",
        "    value,counts = np.unique(y,return_counts=True)\n",
        "    return value[np.argmax(counts)]\n",
        "\n",
        "  def score(self,X,y):\n",
        "    y_preds = self.predict(X)\n",
        "    return np.mean(y_preds==y)\n",
        "\n"
      ],
      "metadata": {
        "id": "xsEPiDEaCA8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load Iris data\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "\n",
        "# For simplicity, let's do a binary classification: class 0 vs not 0\n",
        "y_binary = (y == 0).astype(int)\n",
        "\n",
        "# Split into train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.3, random_state=42)\n",
        "\n",
        "\n",
        "tree = DecisionTreeScratch(max_depth=3, min_samples_split=5)\n",
        "tree.fit(X_train, y_train)\n",
        "\n",
        "print(\"Train accuracy:\", tree.score(X_train, y_train))\n",
        "print(\"Test accuracy:\", tree.score(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpFVgyNmjra-",
        "outputId": "ed979ad7-4c1c-468d-eb56-d8abcee6b5db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy: 1.0\n",
            "Test accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomForestScratch: #literally just a bunch of decision trees predict on it then get majority vote XD\n",
        "  def __init__(self, max_depth = 5,min_samples_split = 5,num_trees=10):\n",
        "    self.max_depth = max_depth\n",
        "    self.min_samples_split = min_samples_split\n",
        "    self.num_trees = num_trees\n",
        "    self.trees = []\n",
        "\n",
        "\n",
        "  def _bootstrap_samples(self,X,y): #get samples using replacement\n",
        "    num_samples = X.shape[0]\n",
        "    indices = np.random.choice(num_samples,size=num_samples,replace=True)\n",
        "    X_bootstrap = X[indices]\n",
        "    y_bootstrap = y[indices]\n",
        "    return X_bootstrap,y_bootstrap\n",
        "\n",
        "  def fit(self,X,y):\n",
        "    for i in range(self.num_trees):\n",
        "      X_bootstrap,y_bootstrap = self._bootstrap_samples(X,y)\n",
        "      new_tree = DecisionTreeScratch(self.max_depth,self.min_samples_split)\n",
        "      new_tree.fit(X_bootstrap,y_bootstrap)\n",
        "      self.trees.append(new_tree)\n",
        "\n",
        "  def predict(self,X):\n",
        "    all_preds = []\n",
        "\n",
        "    for tree in self.trees:\n",
        "        preds = tree.predict(X)\n",
        "        all_preds.append(preds)\n",
        "\n",
        "    all_preds = np.array(all_preds)\n",
        "    all_preds = all_preds.T\n",
        "    final_preds = [np.bincount(row).argmax() for row in all_preds]\n",
        "    return np.array(final_preds)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mAI31Tx4lJU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "# Class 0: centered at (0,0)\n",
        "X_class0 = np.random.randn(50, 2) * 0.5 + np.array([0, 0])\n",
        "\n",
        "# Class 1: centered at (2,2)\n",
        "X_class1 = np.random.randn(50, 2) * 0.5 + np.array([2, 2])\n",
        "\n",
        "X_train = np.vstack((X_class0, X_class1))\n",
        "y_train = np.array([0]*50 + [1]*50)\n",
        "\n",
        "indices = np.arange(len(y_train))\n",
        "np.random.shuffle(indices)\n",
        "X_train = X_train[indices]\n",
        "y_train = y_train[indices]\n",
        "\n",
        "X_test = np.array([\n",
        "    [0, 0],    # close to class 0\n",
        "    [2, 2],    # close to class 1\n",
        "    [1, 1],    # in between\n",
        "    [3, 3],    # far class 1\n",
        "    [-1, -1]   # far class 0\n",
        "])\n",
        "\n",
        "# Create, train and predict\n",
        "rf = RandomForestScratch(max_depth=5, min_samples_split=2, num_trees=10)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "print(\"Test predictions:\", y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19CeqLqwmehh",
        "outputId": "6e4721e2-dbf3-4bae-c347-0237fcfef960"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test predictions: [0 1 1 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "\n",
        "class knnScratch:\n",
        "  def __init__(self,k):\n",
        "    self.k = k\n",
        "\n",
        "  def fit(self,X,y):\n",
        "    self.X_train = X\n",
        "    self.y_train = y\n",
        "\n",
        "  def predict(self, x):\n",
        "      diff = self.X_train - x  # broadcast subtraction\n",
        "      distances = np.sum(diff ** 2, axis=1)  # squared Euclidean distances for all training samples\n",
        "      k_indices = np.argsort(distances)[:self.k]\n",
        "\n",
        "      # Get the labels of those k nearest neighbors\n",
        "      k_labels = self.y_train[k_indices]\n",
        "\n",
        "      majority_label = Counter(k_labels).most_common(1)[0][0]\n",
        "      return majority_label\n",
        "\n",
        "\n",
        "  def predict_batch(self, X):\n",
        "      return [self.predict(x) for x in X]"
      ],
      "metadata": {
        "id": "sWPYtFpD1jQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X_train = np.array([[1,2], [2,3], [3,4], [5,5]])\n",
        "y_train = np.array([0, 0, 1, 1])\n",
        "\n",
        "model = knnScratch(k=3)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "X_test = np.array([[2,2], [4,4]])\n",
        "predictions = model.predict_batch(X_test)\n",
        "print(predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9C2kgwT1o8T",
        "outputId": "64fbe73f-c603-44bd-d9e9-3407868b0b29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[np.int64(0), np.int64(1)]\n"
          ]
        }
      ]
    }
  ]
}