# Machine Learning Models from Scratch

This repository contains implementations of fundamental machine learning algorithms **from scratch** using Python and NumPy, with no use of high-level ML libraries for the core logic.

Itâ€™s designed as a practical introduction to supervised learning methods and showcases how these models work internally.

## Models Implemented

- **Linear Regression**  
  Predict continuous targets using least squares fitting.

- **Logistic Regression**  
  Binary classification with sigmoid activation and cross-entropy loss.

- **Decision Trees**  
  Recursive partitioning to split data based on feature values, for classification or regression.

- **Random Forest**  
  Ensemble of decision trees with bootstrap aggregation to improve accuracy and reduce overfitting.

- **K-Nearest Neighbors (KNN)**  
  Instance-based classification/regression using proximity in feature space.

- **Neural Networks**  
  Classic feedforward neural network with customizable activation functions (ReLU, Sigmoid), implemented with forward pass and backpropagation.

## Features

- Modular, easy-to-understand code structure  
- Step-by-step training and prediction methods  
- Evaluation using common metrics and visualizations  
- Ready-to-run example notebooks demonstrating each algorithm

## Getting Started

1. Clone the repository:
   ```bash
   git clone https://github.com/AlexanderDsouza/MLNotebookScratch.git
   cd MLNotebookScratch


2. Install dependencies:
   ```bash
   pip install numpy scikit-learn 
